---
params:
    cpus: 1
    meta: NULL
    input_dir: "../../results/10_mofa/11_easier"
    artifact_dir: "/local/scratch/sturm/mofa"
    include_tracerx: "true"
---

```{r setup, include=FALSE, message=FALSE}
INCLUDE_TRACERX <- (params$include_tracerx == "true")
knitr::opts_chunk$set(echo = TRUE, dpi = 300, dev = "png", fig.path = "figures/")
dir.create(params$artifact_dir, showWarnings = FALSE)

library(conflicted)
library(MOFA2)
library(reticulate)
library(dplyr)
conflict_prefer("filter", "dplyr")
library(ComplexHeatmap)
library(RColorBrewer)
library(ggpubr)
library(ggplot2)
library(cowplot)
library(tidyr)
library(tibble)
library(corrplot)
library(rstatix)
library(stringr)
library(ggbeeswarm)
library(BayesFactor)
library(ggrepel)
```

```{r}
#' Bring features into 'tidy' format required by MOFA
processFeatures <- function(data, dataset_id) {
  add_patient_col <- function(df) {
    if (dataset_id %in% c("Jia", "Sharma", "TRACERx")) {
      df %>%
        separate("sample", c("patient", "replicate"), remove = FALSE) %>%
        # exclude normal samples
        filter(replicate != "N") %>%
        select(-replicate) %>%
        # prefix with dataset
        mutate(patient = paste0(dataset_id, "-", patient)) %>%
        mutate(sample = paste0(dataset_id, "-", sample))
    } else {
      df %>% mutate(patient = sample)
    }
  }

  do_pivot <- function(df, view) {
    df %>%
      as_tibble(rownames = "sample") %>%
      pivot_longer(cols = -sample, names_to = "feature") %>%
      mutate(view = !!view) %>%
      add_patient_col()
  }

  cellfrac.df <- data$cellfrac[[dataset_id]] %>%
    as.data.frame() %>%
    # fix naming CD8
    rename(`CD8 T` = `CD8+ T`) %>%
    # summarise Tregs and CD4, but keep treg estimate.
    # quanTIseq tends to over-estimate Tregs and under-estimate non-reg. CD4 Ts.
    mutate(`CD4 T` = `CD4 T` + `Treg`) %>%
    do_pivot("Immune cells quantification") %>%
    # DCs and Monocytes show unstable results in the different bootstraps -> exclude them.
    filter(!(feature %in% c("Other", "DC", "Monocyte")))
  pathways.df <- do_pivot(scale(data$pathway[[dataset_id]]), "Pathway scores")
  tfs.df <- do_pivot(scale(data$tf[[dataset_id]]), "Transcription factors")
  response.df <- do_pivot(data$immresp[[dataset_id]], "immune response")

  feature_df <- bind_rows(cellfrac.df, pathways.df, tfs.df, response.df) %>%
    mutate(group = dataset_id, dataset = dataset_id)

  return(feature_df)
}
```

```{r loaddata}
gtex_data <- readRDS(file.path(params$input_dir, "GTEx_expr_data.features.rds"))
nsclc_data <- readRDS(file.path(params$input_dir, "NSCLC_expr_data_sel.features.rds"))
if (INCLUDE_TRACERX) {
  tracerx_data <- readRDS(file.path(params$input_dir, "TRACERx_expr_data.features.rds"))
}
tcga_data <- readRDS(file.path(params$input_dir, "TCGA_expr_data.features.rds"))
data_all <- tcga_data

# Merge and rename datasets
# LUAD and LUSC are contained in both tcga and nsclc. They are identical
# and we use the version contained in the TCGA object.
for (slot in names(gtex_data)) {
  data_all[[slot]][["GTEx"]] <- gtex_data[[slot]][["Lung"]]
  data_all[[slot]][["Jia"]] <- nsclc_data[[slot]][["Jia2018"]]
  data_all[[slot]][["Sharma"]] <- nsclc_data[[slot]][["Sharma2019"]]
  if (INCLUDE_TRACERX) {
    data_all[[slot]][["TRACERx"]] <- tracerx_data[[slot]][["TRACERx"]]
  }
}
DATASETS <- names(data_all$count)
```

## Compute consensus immune response score
```{r response_score}
# List of selected immune response scores
selscores <- c(
  "CYT",
  "Roh_IS",
  "chemokines",
  "Davoli_IS",
  "IFNy",
  "Ayers_expIS",
  "Tcell_inflamed",
  "resF_down",
  "TLS"
)


# Rotation of the "Chemokines" score to agree with "CYT" direction
data_all$immresp <- sapply(data_all$immresp, function(tmp_immresp) {
  chemosign <- sign(cor(tmp_immresp[, "CYT"], tmp_immresp[, "chemokines"]))
  if (chemosign < 0) tmp_immresp[, "chemokines"] <- -tmp_immresp[, "chemokines"]
  tmp_immresp <- tmp_immresp[, selscores]
  tmp_immresp
}, USE.NAMES = TRUE, simplify = FALSE)

# Compute mean/sd for TCGA as base for z-scoring response scores
immresp_tcga <- bind_rows(data_all$immresp[names(tcga_data$immresp)])
immscoreZ <- data.frame(
  score = colnames(immresp_tcga),
  mean = apply(immresp_tcga, 2, mean),
  sd = apply(immresp_tcga, 2, sd)
)

# Computation of the median scaled response
data_all$immresp <- sapply(data_all$immresp, function(tmp_immresp) {
  tmpZ <- immscoreZ[colnames(tmp_immresp), ]
  response <- ((t(tmp_immresp) - tmpZ$mean) / tmpZ$sd)
  response <- apply(response, 2, median)
  tmp_immresp$response <- response
  tmp_immresp
}, USE.NAMES = TRUE, simplify = FALSE)
```

## Process features
```{r processfeatures}
data_all_tidy <- sapply(DATASETS, function(dataset_id) {
  processFeatures(data_all, dataset_id)
}, simplify = FALSE, USE.NAMES = TRUE)

# We want to keep JiaSharma a multigroup model
data_all_tidy$JiaSharma <- bind_rows(data_all_tidy$Jia, data_all_tidy$Sharma) %>% mutate(dataset = "JiaSharma")
data_all_tidy$NSCLC <- bind_rows(data_all_tidy$LUAD, data_all_tidy$LUSC) %>% mutate(group = "NSCLC", dataset = "NSCLC")

data_all_tidy <- data_all_tidy %>% bind_rows()

saveRDS(data_all_tidy, file = file.path(params$artifact_dir, "data_all_tidy.rds"), compress = FALSE)
```

## Process features for MOFA
```{r processfeatures_mofa}
feature_data <- sapply(data_all_tidy$dataset %>% unique(), function(dataset_id) {
  data_all_tidy %>%
    filter(dataset == dataset_id) %>%
    select(-dataset) %>%
    filter(view %in% c("Immune cells quantification", "Transcription factors", "Pathway scores")) %>%
    mutate(value = if_else(view == "Immune cells quantification", log10(value * 100 + 0.001), value))
}, simplify = FALSE, USE.NAMES = TRUE)

feature_data$JiaSharma <- bind_rows(feature_data$Jia, feature_data$Sharma)
feature_data$NSCLC <- bind_rows(feature_data$LUAD, feature_data$LUSC) %>% mutate(group = "NSCLC")
```

### save feature data
```{r}
lapply(names(feature_data), function(dataset_id) {
  saveRDS(feature_data[[dataset_id]], file = file.path(params$artifact_dir, paste0("mofa_", dataset_id, ".rds")), compress = FALSE)
})
```


```{r, message=FALSE}
# Build random bootstrap datasets for each dataset
N_BOOTSTRAP <- 100
bootstrap_datasets <- sapply(DATASETS, function(dataset_id) {
  samples <- feature_data[[dataset_id]]$sample %>% unique()
  lapply(1:N_BOOTSTRAP, function(i) {
    set.seed(i)
    # make new sample ids unique (required for MOFA)!
    sample_df <- tibble(sample = sample(samples, replace = TRUE)) %>%
      mutate(sample_id = row_number())
    feature_data[[dataset_id]] %>%
      right_join(sample_df) %>%
      mutate(sample = paste0(sample, "_", sample_id))
  })
}, simplify = FALSE, USE.NAMES = TRUE)

bootstrap_datasets$JiaSharma <- lapply(1:N_BOOTSTRAP, function(i) {
  bind_rows(
    bootstrap_datasets$Jia[[i]],
    bootstrap_datasets$Sharma[[i]]
  )
})
bootstrap_datasets$NSCLC <- lapply(1:N_BOOTSTRAP, function(i) {
  bind_rows(bootstrap_datasets$LUAD[[i]], bootstrap_datasets$LUSC[[i]])
})
```

### save bootstrap datasets
```{r}
lapply(names(bootstrap_datasets), function(dataset_id) {
  lapply(1:N_BOOTSTRAP, function(i) {
    saveRDS(bootstrap_datasets[[dataset_id]][[i]],
      file = file.path(params$artifact_dir, paste0(
        "mofa_boot_", dataset_id, "_", str_pad(i, 4, pad = "0"), ".rds"
      )), compress = FALSE
    )
  })
})
```


